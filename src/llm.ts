import { InferenceClient } from "@huggingface/inference";

const client = new InferenceClient(process.env.HF_TOKEN);


// –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
const examples = [
  "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —Ç–≤–æ–π –¥–µ–Ω—å?",
  "–°–µ–≥–æ–¥–Ω—è –æ—Ç–ª–∏—á–Ω–∞—è –ø–æ–≥–æ–¥–∞ –¥–ª—è –ø—Ä–æ–≥—É–ª–∫–∏!",
  "–ù–µ –∑–∞–±—É–¥—å –≤—ã–ø–∏—Ç—å –≤–æ–¥—ã!",
  "–í—Ä–µ–º—è –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ –ø–µ—Ä–µ—Ä—ã–≤–∞!",
  "–ö–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞?",
  "–ù–∞–¥–µ—é—Å—å, —É —Ç–µ–±—è —Ö–æ—Ä–æ—à–∏–π –¥–µ–Ω—å!",
  "–ù–µ –∑–∞–±—É–¥—å —É–ª—ã–±–Ω—É—Ç—å—Å—è!",
  "–í—Ä–µ–º—è –¥–ª—è —á–∞—à–µ—á–∫–∏ —á–∞—è!",
  "–ö–∞–∫ –ø—Ä–æ—à—ë–ª —Ç–≤–æ–π –¥–µ–Ω—å?",
  "–ù–∞–¥–µ—é—Å—å, —Ç—ã —Ö–æ—Ä–æ—à–æ –æ—Ç–¥–æ—Ö–Ω—É–ª!"
];


export async function generateMessage(prompt?: string): Promise<string> {
  try {
    console.log('üîç GENERATING MESSAGE - Prompt:', prompt);
    const result = await client.chatCompletion({
      provider: "hf-inference",
      model: 'deepseek-ai/DeepSeek-R1-0528', // –æ—á–µ–Ω—å –¥–æ–ª–≥–∞—è, 685B params
      // model: 'Qwen/Qwen3-235B-A22B', // –¥–æ–ª–≥–∞—è
      // model: 'Qwen/Qwen2.5-7B-Instruct-1M',

      messages: [
        {
          role: "user",
          content: `${prompt || ''}\n\n –ü—Ä–∏–º–µ—Ä—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏: ${examples.join('\n')}`,
        },
      ],
      parameters: {
        max_new_tokens: 500,
        temperature: 0.7,
        top_p: 0.9,
      }
    });

    // –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    let message = (result.choices[0].message.content || '')
      .replace(/\n/g, ' ')
      // <think>...</think>
      .replace(/<think>(.*?)<\/think>/gm, '')
      .trim();

    console.log('üîç Generated message:', { message });

    // –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–∏–º–µ—Ä
    if (message.length < 10) {
      // fallback
      return 'HF_JSON_ERROR';
    }

    return message;
  } catch (error) {
    // fallback
    console.error('–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è:', error);
    // –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É
    return 'HF_JSON_ERROR';
  }
}

// –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ —Å–∞–º–æ–π –ø—Ä–æ—Å—Ç–æ–π LLM (gpt2)
export async function minimalTestLLM() {
  try {
    const chatCompletion = await client.chatCompletion({
      provider: "hf-inference",
      model: "Qwen/Qwen3-235B-A22B",
      messages: [
        {
          role: "user",
          content: "What is the capital of France?",
        },
      ],
    });

    console.log('–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç LLM:', chatCompletion.choices[0].message.content);
    return chatCompletion.choices[0].message.content;
  } catch (error) {
    console.error('–û—à–∏–±–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM:', error);
    return null;
  }
} 
