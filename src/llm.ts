import { InferenceClient } from '@huggingface/inference';
import fs from 'fs';
import { llmLogger } from './logger';
import { cleanLLMText } from './utils/clean-llm-text';
import { extractJsonFromLLM } from './utils/extract-json-from-llm';
import { isLLMError } from './utils/llm-error-check';

const client = new InferenceClient(process.env.HF_TOKEN);

// –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
const examples = [
  '–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —Ç–≤–æ–π –¥–µ–Ω—å?',
  '–°–µ–≥–æ–¥–Ω—è –æ—Ç–ª–∏—á–Ω–∞—è –ø–æ–≥–æ–¥–∞ –¥–ª—è –ø—Ä–æ–≥—É–ª–∫–∏!',
  '–ù–µ –∑–∞–±—É–¥—å –≤—ã–ø–∏—Ç—å –≤–æ–¥—ã!',
  '–í—Ä–µ–º—è –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ –ø–µ—Ä–µ—Ä—ã–≤–∞!',
  '–ö–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞?',
  '–ù–∞–¥–µ—é—Å—å, —É —Ç–µ–±—è —Ö–æ—Ä–æ—à–∏–π –¥–µ–Ω—å!',
  '–ù–µ –∑–∞–±—É–¥—å —É–ª—ã–±–Ω—É—Ç—å—Å—è!',
  '–í—Ä–µ–º—è –¥–ª—è —á–∞—à–µ—á–∫–∏ —á–∞—è!',
  '–ö–∞–∫ –ø—Ä–æ—à—ë–ª —Ç–≤–æ–π –¥–µ–Ω—å?',
  '–ù–∞–¥–µ—é—Å—å, —Ç—ã —Ö–æ—Ä–æ—à–æ –æ—Ç–¥–æ—Ö–Ω—É–ª!',
];

export async function generateMessage(prompt?: string): Promise<string> {
  const startTime = Date.now();
  try {
    const model = 'deepseek-ai/DeepSeek-R1-0528'; // –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è —Ä–∞–±–æ—á–∞—è –º–æ–¥–µ–ª—å
    llmLogger.info({ model, promptLength: prompt?.length || 0, prompt }, `ü§ñ –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LLM`);

    const stream = client.chatCompletionStream({
      provider: 'novita',
      model: 'deepseek-ai/DeepSeek-R1-0528',

      messages: [
        {
          role: 'system',
          content:
            '–¢—ã –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫-–ª—è–≥—É—à–∫–∞ (–º—É–∂—Å–∫–æ–≥–æ —Ä–æ–¥–∞), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª—é–¥–µ–π —Ç–µ–ø–ª—ã–º–∏ –∏ –º–æ—Ç–∏–≤–∏—Ä—É—é—â–∏–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ò—Å–ø–æ–ª—å–∑—É–π –º—É–∂—Å–∫–æ–π —Ä–æ–¥ –≤ —Ä–µ—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "—è —Ä–∞–¥", "—è –≥–æ—Ç–æ–≤", "—è –ø–æ–Ω—è–ª"). –í–ê–ñ–ù–û: –ì–µ–Ω–µ—Ä–∏—Ä—É–π –¢–û–õ–¨–ö–û –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –ë–ï–ó —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π –∏ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ —Ç–∏–ø–∞ "–ú—ã—Å–ª–∏:", "–û—Ç–≤–µ—Ç:".',
        },
        {
          role: 'user',
          content: prompt || `–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞. –ü—Ä–∏–º–µ—Ä—ã: ${examples.join('\n')}`,
        },
      ],
      parameters: {
        max_new_tokens: 500,
        temperature: 0.7,
        top_p: 0.9,
      },
    });

    let fullMessage = '';
    let chunkCount = 0;

    // –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –≤ –ø–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullMessage += content;
        chunkCount++;

        // –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —á–∞–Ω–∫–æ–≤
        if (chunkCount % 10 === 0) {
          llmLogger.trace({ chunkCount, totalLength: fullMessage.length }, `üîÑ –ü–æ–ª—É—á–µ–Ω —á–∞–Ω–∫ ${chunkCount}`);
        }
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info(
      { chunkCount, finalLength: fullMessage.length, duration },
      `‚úÖ LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ ${duration}ms`
    );

    // –õ–æ–≥–∏—Ä—É–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM
    llmLogger.info(
      {
        model,
        fullMessage,
        messageLength: fullMessage.length,
      },
      '‚úçÔ∏è‚úçÔ∏è‚úçÔ∏è –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM'
    );

    // –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    // –î–ª—è JSON –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    let message = prompt && prompt.includes('JSON') ? extractJsonFromLLM(fullMessage) : cleanLLMText(fullMessage);

    // –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ JSON –∑–∞–ø—Ä–æ—Å–æ–≤
    if (prompt && prompt.includes('JSON')) {
      llmLogger.info(
        {
          model,
          promptIncludesJSON: true,
          originalLength: fullMessage.length,
          cleanedLength: message.length,
          originalPreview: fullMessage.substring(0, 200),
          cleanedMessage: message.substring(0, 200),
        },
        '–û—Ç–ª–∞–¥–∫–∞ JSON –∑–∞–ø—Ä–æ—Å–∞'
      );
    }

    // –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
    if (message.length < 10) {
      llmLogger.error(
        {
          model,
          messageLength: message.length,
          originalLength: fullMessage.length,
          preview: fullMessage.substring(0, 100),
          cleanedPreview: message,
        },
        '–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏'
      );
      return 'HF_JSON_ERROR';
    }

    // –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏
    // –ù–û –Ω–µ –¥–ª—è JSON –æ—Ç–≤–µ—Ç–æ–≤ —Å think —Ç–µ–≥–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤–∞–ª–∏–¥–Ω—ã –ø–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    const isJsonRequest = prompt && prompt.includes('JSON');
    if (isJsonRequest) {
      // –î–ª—è JSON –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –∞ –Ω–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π
      const errorCheckResult = isLLMError(message, message);
      llmLogger.debug(
        {
          isJsonRequest,
          messageLength: message.length,
          errorCheckResult,
          messagePreview: message.substring(0, 300),
        },
        '–ü—Ä–æ–≤–µ—Ä–∫–∞ JSON –Ω–∞ –æ—à–∏–±–∫–∏'
      );

      if (errorCheckResult) {
        llmLogger.error(
          {
            model,
            originalText: fullMessage.substring(0, 100),
            cleanedText: message.substring(0, 100),
            cleanedTextLength: message.length,
            reason: 'JSON error check failed',
          },
          '–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ –≤ JSON –æ—Ç–≤–µ—Ç–µ LLM'
        );
        return 'HF_JSON_ERROR';
      }
    } else {
      // –î–ª—è –æ–±—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞
      if (isLLMError(fullMessage, message)) {
        llmLogger.error(
          {
            model,
            originalText: fullMessage.substring(0, 100),
            cleanedText: message.substring(0, 100),
            reason: 'Text error check failed',
          },
          '–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ LLM'
        );
        return 'HF_JSON_ERROR';
      }
    }

    return message;
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
        model: 'deepseek-ai/DeepSeek-R1-0528',
      },
      '–û—à–∏–±–∫–∞ LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏'
    );
    return 'HF_JSON_ERROR';
  }
}

// –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
export async function minimalTestLLM() {
  const startTime = Date.now();
  const model = 'Qwen/Qwen3-235B-A22B';
  const testPrompt = 'What is the capital of France?';

  try {
    llmLogger.info({ model, promptLength: testPrompt.length, prompt: testPrompt }, 'ü§ñ –ù–∞—á–∞–ª–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ LLM');

    const stream = client.chatCompletionStream({
      provider: 'novita', // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä
      model,
      messages: [
        {
          role: 'user',
          content: testPrompt,
        },
      ],
    });

    let fullResponse = '';
    let chunkCount = 0;

    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullResponse += content;
        chunkCount++;
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info(
      { chunkCount, finalLength: fullResponse.length, duration },
      `‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ ${duration}ms`
    );

    return fullResponse.trim();
  } catch (e) {
    const error = e as Error;
    llmLogger.error({ error: error.message, stack: error.stack, model }, '–û—à–∏–±–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ LLM');
    return null;
  }
}

// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
export async function generateUserResponse(
  userMessage: string,
  lastBotMessage?: string,
  calendarEvents?: string
): Promise<string> {
  const startTime = Date.now();
  try {
    // –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    const promptPath = './assets/prompts/user-response.md';
    const userResponsePrompt = fs.readFileSync(promptPath, 'utf-8');

    const model = 'deepseek-ai/DeepSeek-R1-0528';
    llmLogger.info(
      { model, userMessageLength: userMessage.length, userMessage, lastBotMessage, calendarEvents },
      'ü§ñ –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é'
    );

    // –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    let contextMessage = userResponsePrompt + '\n\n';

    if (lastBotMessage) {
      contextMessage += `**–ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –±–æ—Ç–∞:**\n${lastBotMessage}\n\n`;
    }

    if (calendarEvents) {
      contextMessage += `**–°–æ–±—ã—Ç–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è:**\n${calendarEvents}\n\n`;
    }

    contextMessage += `**–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**\n${userMessage}\n\n`;
    contextMessage += '–î–∞–π –∫—Ä–∞—Ç–∫–∏–π, —Ç–µ–ø–ª—ã–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π –æ—Ç–≤–µ—Ç (–¥–æ 300 —Å–∏–º–≤–æ–ª–æ–≤):';

    llmLogger.info({ contextMessageLength: contextMessage.length, contextMessage }, 'üìù –ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM');

    const stream = client.chatCompletionStream({
      provider: 'novita',
      model,
      messages: [
        {
          role: 'user',
          content: contextMessage,
        },
      ],
      parameters: {
        max_new_tokens: 200,
        temperature: 0.8,
        top_p: 0.9,
      },
    });

    let fullResponse = '';
    let chunkCount = 0;

    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullResponse += content;
        chunkCount++;

        if (chunkCount % 5 === 0) {
          llmLogger.trace({ chunkCount, totalLength: fullResponse.length }, 'üîÑ –ü–æ–ª—É—á–µ–Ω —á–∞–Ω–∫ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é');
        }
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info(
      { chunkCount, finalLength: fullResponse.length, duration },
      `‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ ${duration}ms`
    );

    // –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    let response = cleanLLMText(fullResponse);

    // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
    if (response.length > 300) {
      response = response.substring(0, 297) + '...';
    }

    // –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
    if (response.length < 5) {
      llmLogger.error({ model, responseLength: response.length }, '–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π');
      return '–°–ø–∞—Å–∏–±–æ, —á—Ç–æ –ø–æ–¥–µ–ª–∏–ª—Å—è! ü§ç';
    }

    return response;
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
        model: 'deepseek-ai/DeepSeek-R1-0528',
      },
      '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é'
    );

    // Fallback –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
    return '–°–ø–∞—Å–∏–±–æ, —á—Ç–æ –ø–æ–¥–µ–ª–∏–ª—Å—è! ü§ç';
  }
}

// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞
export async function generateFrogImage(prompt: string): Promise<Buffer | null> {
  const startTime = Date.now();
  try {
    const model = 'black-forest-labs/FLUX.1-dev';
    llmLogger.info({ model, promptLength: prompt.length, prompt }, `üé® –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏`);

    const response = await client.textToImage({
      model,
      inputs: prompt,
      parameters: {
        width: 512,
        height: 512,
        guidance_scale: 7.5,
        num_inference_steps: 20,
      },
    });

    const duration = Date.now() - startTime;

    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –æ—Ç–≤–µ—Ç–∞
    let buffer: Buffer;

    try {
      if (response && typeof response === 'object' && 'arrayBuffer' in response) {
        const arrayBuffer = await (response as any).arrayBuffer();
        buffer = Buffer.from(arrayBuffer);
      } else if (Buffer.isBuffer(response)) {
        buffer = response;
      } else {
        // –ü—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ ArrayBuffer –∏–ª–∏ –¥—Ä—É–≥–æ–π —Ç–∏–ø
        buffer = Buffer.from(response as any);
      }

      llmLogger.info({ duration, imageSize: buffer.length }, `‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª—è–≥—É—à–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∑–∞ ${duration}ms`);
      return buffer;
    } catch (conversionError) {
      llmLogger.error(
        {
          model,
          responseType: typeof response,
          conversionError: (conversionError as Error).message,
        },
        '–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π'
      );
      return null;
    }
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
        model: 'black-forest-labs/FLUX.1-dev',
      },
      '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏'
    );
    return null;
  }
}

// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
export async function generateFrogPrompt(
  userMessage: string,
  calendarEvents?: string,
  lastBotMessage?: string
): Promise<string> {
  const startTime = Date.now();
  try {
    // –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è –ª—è–≥—É—à–∫–∏
    const promptPath = './assets/prompts/frog-image-prompt.md';
    const frogPromptTemplate = fs.readFileSync(promptPath, 'utf-8');

    const model = 'deepseek-ai/DeepSeek-R1-0528';
    llmLogger.info(
      { model, userMessageLength: userMessage.length, userMessage, lastBotMessage, calendarEvents },
      'üé® –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ª—è–≥—É—à–∫–∏'
    );

    // –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    let contextMessage = frogPromptTemplate + '\n\n';

    // –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    const today = new Date();
    const dateString = today.toLocaleDateString('ru-RU', {
      weekday: 'long',
      year: 'numeric',
      month: 'long',
      day: 'numeric',
    });
    contextMessage += `**–°–µ–≥–æ–¥–Ω—è:** ${dateString}\n\n`;

    if (lastBotMessage) {
      contextMessage += `**–ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –±–æ—Ç–∞:**\n${lastBotMessage}\n\n`;
    }

    contextMessage += `**–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**\n${userMessage}\n\n`;

    if (calendarEvents) {
      contextMessage += `**–°–æ–±—ã—Ç–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è:**\n${calendarEvents}\n\n`;
    }

    contextMessage += '–°–æ–∑–¥–∞–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏ (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –¥–æ 200 —Å–∏–º–≤–æ–ª–æ–≤):';

    llmLogger.info(
      { contextMessageLength: contextMessage.length, contextMessage },
      'üìù –ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞ –ª—è–≥—É—à–∫–∏'
    );

    const stream = client.chatCompletionStream({
      provider: 'novita',
      model,
      messages: [
        {
          role: 'user',
          content: contextMessage,
        },
      ],
      parameters: {
        max_new_tokens: 100,
        temperature: 0.9,
        top_p: 0.95,
      },
    });

    let fullResponse = '';
    let chunkCount = 0;

    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullResponse += content;
        chunkCount++;
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info(
      { chunkCount, finalLength: fullResponse.length, duration },
      `‚úÖ –ü—Ä–æ–º–ø—Ç –¥–ª—è –ª—è–≥—É—à–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∑–∞ ${duration}ms`
    );

    // –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    let prompt = cleanLLMText(fullResponse).replace(/"/g, ''); // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —É–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

    // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞
    if (prompt.length > 200) {
      prompt = prompt.substring(0, 197) + '...';
    }

    // –ï—Å–ª–∏ –ø—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
    if (prompt.length < 10) {
      llmLogger.error({ model, promptLength: prompt.length }, '–ü—Ä–æ–º–ø—Ç –¥–ª—è –ª—è–≥—É—à–∫–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π');
      return 'anthropomorphic frog portrait, friendly psychologist, warm smile, soft lighting, digital art, looking at viewer';
    }

    return prompt;
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
        model: 'deepseek-ai/DeepSeek-R1-0528',
      },
      '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ª—è–≥—É—à–∫–∏'
    );

    // Fallback –ø—Ä–æ–º–ø—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
    return 'anthropomorphic frog portrait, friendly psychologist, warm smile, soft lighting, digital art, looking at viewer';
  }
}

// –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å –Ω–∏–∑–∫–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π (–¥–ª—è JSON –æ—Ç–≤–µ—Ç–æ–≤)
export async function analyzeWithLowTemp(prompt: string): Promise<string> {
  const startTime = Date.now();
  try {
    const model = 'deepseek-ai/DeepSeek-R1-0528';
    llmLogger.info({ model, promptLength: prompt.length }, `üîç –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –Ω–∏–∑–∫–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π`);

    const stream = client.chatCompletionStream({
      provider: 'novita',
      model: 'deepseek-ai/DeepSeek-R1-0528',

      messages: [
        {
          role: 'system',
          content:
            '–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫. –û—Ç–≤–µ—á–∞–π —á–µ—Ç–∫–æ –∏ —Å—Ç—Ä–æ–≥–æ –ø–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. –ì–µ–Ω–µ—Ä–∏—Ä—É–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π.',
        },
        {
          role: 'user',
          content: prompt,
        },
      ],
      parameters: {
        max_new_tokens: 300,
        temperature: 0.2, // –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        top_p: 0.9,
      },
    });

    let fullMessage = '';
    let chunkCount = 0;

    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullMessage += content;
        chunkCount++;
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info({ chunkCount, finalLength: fullMessage.length, duration }, `‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ ${duration}ms`);

    // –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
    const message = extractJsonFromLLM(fullMessage);

    llmLogger.info(
      {
        model,
        extractedJson: message,
        originalLength: fullMessage.length,
      },
      'üîç –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞'
    );

    return message;
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
      },
      '–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å –Ω–∏–∑–∫–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π'
    );
    throw error;
  }
}
