import { InferenceClient } from '@huggingface/inference';
import fs from 'fs';
import { llmLogger } from './logger';

const client = new InferenceClient(process.env.HF_TOKEN);

// –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
const examples = [
  '–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —Ç–≤–æ–π –¥–µ–Ω—å?',
  '–°–µ–≥–æ–¥–Ω—è –æ—Ç–ª–∏—á–Ω–∞—è –ø–æ–≥–æ–¥–∞ –¥–ª—è –ø—Ä–æ–≥—É–ª–∫–∏!',
  '–ù–µ –∑–∞–±—É–¥—å –≤—ã–ø–∏—Ç—å –≤–æ–¥—ã!',
  '–í—Ä–µ–º—è –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ –ø–µ—Ä–µ—Ä—ã–≤–∞!',
  '–ö–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞?',
  '–ù–∞–¥–µ—é—Å—å, —É —Ç–µ–±—è —Ö–æ—Ä–æ—à–∏–π –¥–µ–Ω—å!',
  '–ù–µ –∑–∞–±—É–¥—å —É–ª—ã–±–Ω—É—Ç—å—Å—è!',
  '–í—Ä–µ–º—è –¥–ª—è —á–∞—à–µ—á–∫–∏ —á–∞—è!',
  '–ö–∞–∫ –ø—Ä–æ—à—ë–ª —Ç–≤–æ–π –¥–µ–Ω—å?',
  '–ù–∞–¥–µ—é—Å—å, —Ç—ã —Ö–æ—Ä–æ—à–æ –æ—Ç–¥–æ—Ö–Ω—É–ª!',
];

export async function generateMessage(prompt?: string): Promise<string> {
  const startTime = Date.now();
  try {
    const model = 'deepseek-ai/DeepSeek-R1-0528';
    llmLogger.info({ model, promptLength: prompt?.length || 0 }, `ü§ñ –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LLM`);

    const stream = client.chatCompletionStream({
      provider: 'novita',
      model: 'deepseek-ai/DeepSeek-R1-0528', // –æ—á–µ–Ω—å –¥–æ–ª–≥–∞—è, 685B params
      // model: 'Qwen/Qwen3-235B-A22B', // –¥–æ–ª–≥–∞—è
      // model: 'Qwen/Qwen2.5-7B-Instruct-1M',

      messages: [
        {
          role: 'user',
          content: `${prompt || ''}\n\n –ü—Ä–∏–º–µ—Ä—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏: ${examples.join('\n')}`,
        },
      ],
      parameters: {
        max_new_tokens: 500,
        temperature: 0.7,
        top_p: 0.9,
      },
    });

    let fullMessage = '';
    let chunkCount = 0;

    // –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –≤ –ø–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullMessage += content;
        chunkCount++;

        // –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —á–∞–Ω–∫–æ–≤
        if (chunkCount % 10 === 0) {
          llmLogger.debug({ chunkCount, totalLength: fullMessage.length }, `üîÑ –ü–æ–ª—É—á–µ–Ω —á–∞–Ω–∫ ${chunkCount}`);
        }
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info(
      { chunkCount, finalLength: fullMessage.length, duration },
      `‚úÖ LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ ${duration}ms`
    );

    // –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    let message = fullMessage
      .replace(/\n/g, ' ')
      // <think>...</think> - —É–±–∏—Ä–∞–µ–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
      .replace(/<think>(.*?)<\/think>/gm, '')
      .trim();

    // –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
    if (message.length < 10) {
      llmLogger.error({ model, messageLength: message.length }, '–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ');
      return 'HF_JSON_ERROR';
    }

    return message;
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
        model: 'deepseek-ai/DeepSeek-R1-0528',
      },
      '–û—à–∏–±–∫–∞ LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏'
    );
    return 'HF_JSON_ERROR';
  }
}

// –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
export async function minimalTestLLM() {
  const startTime = Date.now();
  const model = 'Qwen/Qwen3-235B-A22B';

  try {
    llmLogger.info({ model, promptLength: 33 }, 'ü§ñ –ù–∞—á–∞–ª–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ LLM');

    const stream = client.chatCompletionStream({
      provider: 'novita', // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä
      model,
      messages: [
        {
          role: 'user',
          content: 'What is the capital of France?',
        },
      ],
    });

    let fullResponse = '';
    let chunkCount = 0;

    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullResponse += content;
        chunkCount++;
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info(
      { chunkCount, finalLength: fullResponse.length, duration },
      `‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ ${duration}ms`
    );

    return fullResponse.trim();
  } catch (e) {
    const error = e as Error;
    llmLogger.error({ error: error.message, stack: error.stack, model }, '–û—à–∏–±–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ LLM');
    return null;
  }
}

// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
export async function generateUserResponse(userMessage: string, lastBotMessage?: string, calendarEvents?: string): Promise<string> {
  const startTime = Date.now();
  try {
    // –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    const promptPath = './assets/prompts/user-response.md';
    const userResponsePrompt = fs.readFileSync(promptPath, 'utf-8');
    
    const model = 'deepseek-ai/DeepSeek-R1-0528';
    llmLogger.info({ model, userMessageLength: userMessage.length }, 'ü§ñ –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é');

    // –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    let contextMessage = userResponsePrompt + '\n\n';
    
    if (lastBotMessage) {
      contextMessage += `**–ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –±–æ—Ç–∞:**\n${lastBotMessage}\n\n`;
    }
    
    if (calendarEvents) {
      contextMessage += `**–°–æ–±—ã—Ç–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è:**\n${calendarEvents}\n\n`;
    }
    
    contextMessage += `**–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**\n${userMessage}\n\n`;
    contextMessage += '–î–∞–π –∫—Ä–∞—Ç–∫–∏–π, —Ç–µ–ø–ª—ã–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π –æ—Ç–≤–µ—Ç (–¥–æ 300 —Å–∏–º–≤–æ–ª–æ–≤):';

    const stream = client.chatCompletionStream({
      provider: 'novita',
      model,
      messages: [
        {
          role: 'user',
          content: contextMessage,
        },
      ],
      parameters: {
        max_new_tokens: 200,
        temperature: 0.8,
        top_p: 0.9,
      },
    });

    let fullResponse = '';
    let chunkCount = 0;

    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullResponse += content;
        chunkCount++;

        if (chunkCount % 5 === 0) {
          llmLogger.debug({ chunkCount, totalLength: fullResponse.length }, 'üîÑ –ü–æ–ª—É—á–µ–Ω —á–∞–Ω–∫ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é');
        }
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info(
      { chunkCount, finalLength: fullResponse.length, duration },
      `‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ ${duration}ms`
    );

    // –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    let response = fullResponse
      .replace(/\n/g, ' ')
      .replace(/<think>(.*?)<\/think>/gm, '')
      .trim();

    // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
    if (response.length > 300) {
      response = response.substring(0, 297) + '...';
    }

    // –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
    if (response.length < 5) {
      llmLogger.error({ model, responseLength: response.length }, '–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π');
      return '–°–ø–∞—Å–∏–±–æ, —á—Ç–æ –ø–æ–¥–µ–ª–∏–ª—Å—è! ü§ç';
    }

    return response;
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
        model: 'deepseek-ai/DeepSeek-R1-0528',
      },
      '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é'
    );
    
    // Fallback –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
    return '–°–ø–∞—Å–∏–±–æ, —á—Ç–æ –ø–æ–¥–µ–ª–∏–ª—Å—è! ü§ç';
  }
}

// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞
export async function generateFrogImage(prompt: string): Promise<Buffer | null> {
  const startTime = Date.now();
  try {
    const model = 'black-forest-labs/FLUX.1-dev';
    llmLogger.info({ model, promptLength: prompt.length, prompt }, `üé® –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏ —Å –ø—Ä–æ–º–ø—Ç–æ–º: "${prompt}"`);

    const response = await client.textToImage({
      model,
      inputs: prompt,
      parameters: {
        width: 512,
        height: 512,
        guidance_scale: 7.5,
        num_inference_steps: 20,
      },
    });

    const duration = Date.now() - startTime;
    
    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –æ—Ç–≤–µ—Ç–∞
    let buffer: Buffer;
    
    try {
      if (response && typeof response === 'object' && 'arrayBuffer' in response) {
        const arrayBuffer = await (response as any).arrayBuffer();
        buffer = Buffer.from(arrayBuffer);
      } else if (Buffer.isBuffer(response)) {
        buffer = response;
      } else {
        // –ü—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ ArrayBuffer –∏–ª–∏ –¥—Ä—É–≥–æ–π —Ç–∏–ø
        buffer = Buffer.from(response as any);
      }
      
      llmLogger.info(
        { duration, imageSize: buffer.length },
        `‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª—è–≥—É—à–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∑–∞ ${duration}ms`
      );
      return buffer;
    } catch (conversionError) {
      llmLogger.error({ 
        model, 
        responseType: typeof response,
        conversionError: (conversionError as Error).message 
      }, '–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π');
      return null;
    }
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
        model: 'black-forest-labs/FLUX.1-dev',
      },
      '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏'
    );
    return null;
  }
}

// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
export async function generateFrogPrompt(userMessage: string, calendarEvents?: string, lastBotMessage?: string): Promise<string> {
  const startTime = Date.now();
  try {
    // –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è –ª—è–≥—É—à–∫–∏
    const promptPath = './assets/prompts/frog-image-prompt.md';
    const frogPromptTemplate = fs.readFileSync(promptPath, 'utf-8');
    
    const model = 'deepseek-ai/DeepSeek-R1-0528';
    llmLogger.info({ model, userMessageLength: userMessage.length }, 'üé® –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ª—è–≥—É—à–∫–∏');

    // –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    let contextMessage = frogPromptTemplate + '\n\n';
    
    // –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    const today = new Date();
    const dateString = today.toLocaleDateString('ru-RU', {
      weekday: 'long',
      year: 'numeric', 
      month: 'long',
      day: 'numeric'
    });
    contextMessage += `**–°–µ–≥–æ–¥–Ω—è:** ${dateString}\n\n`;
    
    if (lastBotMessage) {
      contextMessage += `**–ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –±–æ—Ç–∞:**\n${lastBotMessage}\n\n`;
    }
    
    contextMessage += `**–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**\n${userMessage}\n\n`;
    
    if (calendarEvents) {
      contextMessage += `**–°–æ–±—ã—Ç–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è:**\n${calendarEvents}\n\n`;
    }
    
    contextMessage += '–°–æ–∑–¥–∞–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª—è–≥—É—à–∫–∏ (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –¥–æ 200 —Å–∏–º–≤–æ–ª–æ–≤):';

    const stream = client.chatCompletionStream({
      provider: 'novita',
      model,
      messages: [
        {
          role: 'user',
          content: contextMessage,
        },
      ],
      parameters: {
        max_new_tokens: 100,
        temperature: 0.9,
        top_p: 0.95,
      },
    });

    let fullResponse = '';
    let chunkCount = 0;

    for await (const chunk of stream) {
      if (chunk.choices && chunk.choices[0]?.delta?.content) {
        const content = chunk.choices[0].delta.content;
        fullResponse += content;
        chunkCount++;
      }
    }

    const duration = Date.now() - startTime;
    llmLogger.info(
      { chunkCount, finalLength: fullResponse.length, duration },
      `‚úÖ –ü—Ä–æ–º–ø—Ç –¥–ª—è –ª—è–≥—É—à–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∑–∞ ${duration}ms`
    );

    // –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    let prompt = fullResponse
      .replace(/\n/g, ' ')
      .replace(/<think>(.*?)<\/think>/gm, '')
      .replace(/"/g, '')
      .trim();

    // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞
    if (prompt.length > 200) {
      prompt = prompt.substring(0, 197) + '...';
    }

    // –ï—Å–ª–∏ –ø—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
    if (prompt.length < 10) {
      llmLogger.error({ model, promptLength: prompt.length }, '–ü—Ä–æ–º–ø—Ç –¥–ª—è –ª—è–≥—É—à–∫–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π');
      return 'anthropomorphic frog portrait, friendly psychologist, warm smile, soft lighting, digital art, looking at viewer';
    }

    return prompt;
  } catch (e) {
    const error = e as Error;
    llmLogger.error(
      {
        error: error.message,
        stack: error.stack,
        model: 'deepseek-ai/DeepSeek-R1-0528',
      },
      '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ª—è–≥—É—à–∫–∏'
    );
    
    // Fallback –ø—Ä–æ–º–ø—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
    return 'anthropomorphic frog portrait, friendly psychologist, warm smile, soft lighting, digital art, looking at viewer';
  }
}
